#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
NBA Daily Results ‚Üí Telegram (RU)

‚Ä¢ –ò—Å—Ç–æ—á–Ω–∏–∫ ‚Ññ1 –¥–ª—è —Å—á—ë—Ç–∞/–∏–≥—Ä–æ–∫–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–æ–º: Sports.ru (–±–æ–∫—Å—Å–∫–æ—Ä).
‚Ä¢ –§–æ–ª–ª–±–µ–∫ –¥–ª—è –∏–≥—Ä–æ–∫–æ–≤/—Å—á—ë—Ç–∞/–û–¢: ESPN site.web.api (—Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä GS‚ÜíGSW, WSH‚ÜíWAS, SA‚ÜíSAS, NY‚ÜíNYK, NO‚ÜíNOP).
‚Ä¢ –ò–º–µ–Ω–∞ –∏–≥—Ä–æ–∫–æ–≤: –µ—Å–ª–∏ –ø—Ä–∏—à–ª–∏ —Å Sports.ru ‚Äî —É–∂–µ —Ä—É—Å—Å–∫–∏–µ; –µ—Å–ª–∏ –∏–∑ ESPN ‚Äî –∏—â–µ–º –ø—Ä–æ—Ñ–∏–ª—å –Ω–∞ Sports.ru –∏ –±–µ—Ä—ë–º ¬´–ò. –§–∞–º–∏–ª–∏—è¬ª,
  –∏–Ω–∞—á–µ –ø—Ä–æ—Å—Ç–æ ¬´–ò. –§–∞–º–∏–ª–∏—è¬ª –ø–æ –ª–∞—Ç–∏–Ω–∏—Ü–µ.
‚Ä¢ –§–æ—Ä–º–∞—Ç: –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–º–∞–Ω–¥ –∏ —ç–º–æ–¥–∑–∏ –≤–∏–¥–Ω—ã, —Å—á—ë—Ç –∏ –∏–≥—Ä–æ–∫–∏ ‚Äî –≤ —Å–ø–æ–π–ª–µ—Ä–∞—Ö. –°—á—ë—Ç –ø–æ–±–µ–¥–∏—Ç–µ–ª—è –∂–∏—Ä–Ω—ã–º. ¬´(–û–¢)¬ª —Ç–æ–ª—å–∫–æ –ø—Ä–∏ >4 –ø–µ—Ä–∏–æ–¥–æ–≤.
‚Ä¢ –ò–≥—Ä–æ–∫–∏: –º–∏–Ω–∏–º—É–º 1, –º–∞–∫—Å–∏–º—É–º 2 –Ω–∞ –∫–æ–º–∞–Ω–¥—É; –≤—Ç–æ—Ä–æ–π ‚Äî –µ—Å–ª–∏ ‚â•20 –æ—á–∫–æ–≤ –∏–ª–∏ –¥–∞–±–ª-–¥–∞–±–ª, –∏–ª–∏ ‚â•6 STL/BLK.
‚Ä¢ –û—Å–æ–±—ã–µ: –µ—Å–ª–∏ –∏–≥—Ä–∞–ª –ï–≥–æ—Ä –î—ë–º–∏–Ω (BKN) –∏–ª–∏ –í–ª–∞–¥ –ì–æ–ª–¥–∏–Ω (MIA) ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∂–∏—Ä–Ω—ã–º, —Å —Ç—Ä–µ–º—è –Ω–∞–∏–±–æ–ª—å—à–∏–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏.
"""

import os, sys, re, json
from datetime import datetime, timedelta, date
from zoneinfo import ZoneInfo
from urllib.parse import urljoin, quote_plus

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from bs4 import BeautifulSoup

# ================== ENV / DEBUG ==================
BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "").strip()
CHAT_ID   = os.getenv("TELEGRAM_CHAT_ID", "").strip()
TEAM_EMOJI_JSON = os.getenv("TEAM_EMOJI_JSON", "").strip()
DEBUG = os.getenv("DEBUG_NBA", "").strip() not in {"", "0", "false", "False"}

def logdbg(*a):
    if DEBUG:
        print("[DBG]", *a, file=sys.stderr)

# ================== RU HELPERS ==================
RU_MONTHS = {1:"—è–Ω–≤–∞—Ä—è",2:"—Ñ–µ–≤—Ä–∞–ª—è",3:"–º–∞—Ä—Ç–∞",4:"–∞–ø—Ä–µ–ª—è",5:"–º–∞—è",6:"–∏—é–Ω—è",
             7:"–∏—é–ª—è",8:"–∞–≤–≥—É—Å—Ç–∞",9:"—Å–µ–Ω—Ç—è–±—Ä—è",10:"–æ–∫—Ç—è–±—Ä—è",11:"–Ω–æ—è–±—Ä—è",12:"–¥–µ–∫–∞–±—Ä—è"}
def ru_date(d: date) -> str: return f"{d.day} {RU_MONTHS[d.month]}"
def ru_plural(n: int, forms: tuple[str,str,str]) -> str:
    n = abs(int(n)) % 100; n1 = n % 10
    if 11 <= n <= 19: return forms[2]
    if 2 <= n1 <= 4:  return forms[1]
    if n1 == 1:      return forms[0]
    return forms[2]

def et_today() -> date:
    return datetime.now(ZoneInfo("America/New_York")).date()

# ================== HTTP ==================
def make_session():
    s = requests.Session()
    r = Retry(total=6, connect=6, read=6, backoff_factor=0.6,
              status_forcelist=[429,500,502,503,504],
              allowed_methods=["GET","POST"])
    s.mount("https://", HTTPAdapter(max_retries=r))
    s.headers.update({
        "User-Agent": "NBA-ResultsBot/7.2 (sportsru primary, espn fallback)",
        "Accept-Language": "ru,en;q=0.7",
    })
    return s
S = make_session()

def _get_json(url: str) -> dict:
    try:
        r = S.get(url, timeout=25)
        if r.status_code != 200: return {}
        return r.json()
    except Exception:
        return {}

# ================== CONSTANTS / MAPS ==================
SPORTS_DAY_TMPL = "https://www.sports.ru/stat/basketball/center/end/{y:04d}/{m:02d}/{d:02d}.html"
MATCH_PREFIX = "https://www.sports.ru/basketball/match/"

# –°–ª–∞–≥ ‚Üí –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä–∞
SLUG2ABBR = {
    "atlanta-hawks":"ATL","boston-celtics":"BOS","brooklyn-nets":"BKN","charlotte-hornets":"CHA",
    "chicago-bulls":"CHI","cleveland-cavaliers":"CLE","dallas-mavericks":"DAL","denver-nuggets":"DEN",
    "detroit-pistons":"DET","golden-state-warriors":"GSW","houston-rockets":"HOU","indiana-pacers":"IND",
    "los-angeles-clippers":"LAC","los-angeles-lakers":"LAL","memphis-grizzlies":"MEM","miami-heat":"MIA",
    "milwaukee-bucks":"MIL","minnesota-timberwolves":"MIN","new-orleans-pelicans":"NOP","new-york-knicks":"NYK",
    "oklahoma-city-thunder":"OKC","orlando-magic":"ORL","philadelphia-76ers":"PHI","phoenix-suns":"PHX",
    "portland-trail-blazers":"POR","sacramento-kings":"SAC","san-antonio-spurs":"SAS","toronto-raptors":"TOR",
    "utah-jazz":"UTA","washington-wizards":"WAS",
}
TEAM_RU = {
    "ATL":"–ê—Ç–ª–∞–Ω—Ç–∞","BOS":"–ë–æ—Å—Ç–æ–Ω","BKN":"–ë—Ä—É–∫–ª–∏–Ω","CHA":"–®–∞—Ä–ª–æ—Ç—Ç","CHI":"–ß–∏–∫–∞–≥–æ","CLE":"–ö–ª–∏–≤–ª–µ–Ω–¥",
    "DAL":"–î–∞–ª–ª–∞—Å","DEN":"–î–µ–Ω–≤–µ—Ä","DET":"–î–µ—Ç—Ä–æ–π—Ç","GSW":"–ì–æ–ª–¥–µ–Ω –°—Ç—ç–π—Ç","HOU":"–•—å—é—Å—Ç–æ–Ω","IND":"–ò–Ω–¥–∏–∞–Ω–∞",
    "LAC":"–ö–ª–∏–ø–ø–µ—Ä—Å","LAL":"–õ–µ–π–∫–µ—Ä—Å","MEM":"–ú–µ–º—Ñ–∏—Å","MIA":"–ú–∞–π–∞–º–∏","MIL":"–ú–∏–ª—É–æ–∫–∏","MIN":"–ú–∏–Ω–Ω–µ—Å–æ—Ç–∞",
    "NOP":"–ù–æ–≤—ã–π –û—Ä–ª–µ–∞–Ω","NYK":"–ù—å—é-–ô–æ—Ä–∫","OKC":"–û–∫–ª–∞—Ö–æ–º–∞-–°–∏—Ç–∏","ORL":"–û—Ä–ª–∞–Ω–¥–æ","PHI":"–§–∏–ª–∞–¥–µ–ª—å—Ñ–∏—è",
    "PHX":"–§–∏–Ω–∏–∫—Å","POR":"–ü–æ—Ä—Ç–ª–µ–Ω–¥","SAC":"–°–∞–∫—Ä–∞–º–µ–Ω—Ç–æ","SAS":"–°–∞–Ω-–ê–Ω—Ç–æ–Ω–∏–æ","TOR":"–¢–æ—Ä–æ–Ω—Ç–æ","UTA":"–Æ—Ç–∞","WAS":"–í–∞—à–∏–Ω–≥—Ç–æ–Ω",
}

# ESPN ‚Üí –Ω–∞—à–∏ –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã
ESPN_ABBR_MAP = {"GS":"GSW", "WSH":"WAS", "SA":"SAS", "NY":"NYK", "NO":"NOP"}

def norm_abbr(ab: str) -> str:
    ab = (ab or "").upper()
    return ESPN_ABBR_MAP.get(ab, ab)

# ESPN API
ESPN_SB  = "https://site.web.api.espn.com/apis/v2/sports/basketball/nba/scoreboard?dates={ymd}"
ESPN_BOX = "https://site.web.api.espn.com/apis/v2/sports/basketball/nba/boxscore?event={eid}"

# ================== EMOJI ==================
def load_team_emojis() -> dict[str,str]:
    if not TEAM_EMOJI_JSON: return {}
    try:
        d = json.loads(TEAM_EMOJI_JSON)
        if isinstance(d, dict):
            return {k.upper(): str(v) for k,v in d.items()}
    except Exception:
        pass
    return {}
TEAM_EMOJI = load_team_emojis()
def team_emoji(abbr: str) -> str:
    val = TEAM_EMOJI.get((abbr or "").upper())
    if not val:
        return "üèÄ"
    if re.fullmatch(r"\d{6,}", val):
        return f'<tg-emoji emoji-id="{val}"></tg-emoji>'
    return val

# ================== UTILS ==================
def abbr_from_url(url: str, side: int) -> str | None:
    m = re.search(r"/basketball/match/([a-z0-9\-]+)-vs-([a-z0-9\-]+)/", url)
    if not m: return None
    slug = m.group(1 + side)
    return SLUG2ABBR.get(slug)

def fetch_day_links(d: date) -> list[str]:
    url = SPORTS_DAY_TMPL.format(y=d.year, m=d.month, d=d.day)
    r = S.get(url, timeout=25)
    if r.status_code != 200:
        logdbg("SPORTS DAY FAIL", url, r.status_code); return []
    soup = BeautifulSoup(r.text, "html.parser")
    out, seen = [], set()
    for a in soup.find_all("a", href=True):
        h = a["href"]
        if not (h.startswith("/basketball/match/") or h.startswith(MATCH_PREFIX)): continue
        full = urljoin("https://www.sports.ru", h).split("#", 1)[0]
        if "vs" not in full: continue
        if not full.endswith("/"): full += "/"
        a_abbr, b_abbr = abbr_from_url(full, 0), abbr_from_url(full, 1)
        if not (a_abbr and b_abbr and a_abbr in TEAM_RU and b_abbr in TEAM_RU): continue
        if full not in seen:
            out.append(full); seen.add(full)
    logdbg("SPORTS LINKS", len(out))
    return out

def detect_ot_by_periods(soup: BeautifulSoup) -> bool:
    for h3 in soup.find_all("h3"):
        t = (h3.get_text(" ", strip=True) or "").lower()
        if "–ø–æ –ø–µ—Ä–∏–æ–¥–∞–º" in t or "–ø–µ—Ä–∏–æ–¥" in t:
            tbl = h3.find_next("table")
            if not tbl: continue
            row = tbl.find("tr")
            if not row: continue
            pairs = re.findall(r"\b\d{1,3}\s*:\s*\d{1,3}\b", row.get_text(" ", strip=True))
            return len(pairs) > 4
    return False

# ================== SPORTS.RU PARSE ==================
def norm_header(s: str) -> str:
    t = re.sub(r"\s+", " ", (s or "").strip().lower())
    t = t.replace("–æ—á–∫–∏", "pts").replace("–ø–µ—Ä–µ–¥–∞—á–∏","ast").replace("–ø–µ—Ä–µ–¥","ast")
    t = t.replace("–ø–æ–¥–±–æ—Ä—ã","reb").replace("–ø–æ–¥–±–æ—Ä","reb")
    t = t.replace("–ø–µ—Ä–µ—Ö–≤–∞—Ç—ã","stl").replace("–ø–µ—Ä–µ—Ö–≤","stl")
    t = t.replace("–±–ª–æ–∫-—à–æ—Ç—ã","blk").replace("–±–ª–æ–∫—à–æ—Ç—ã","blk").replace("–±–ª–æ–∫","blk")
    return t

def map_header_indices(tbl) -> dict[str,int]:
    thead = tbl.find("thead")
    headers = []
    if thead:
        trs = thead.find_all("tr")
        if trs:
            headers = [c.get_text(" ", strip=True) for c in trs[-1].find_all(["th","td"])]
    if not headers:
        first = tbl.find("tr")
        if first:
            headers = [c.get_text(" ", strip=True) for c in first.find_all(["th","td"])]
    idx = {}
    for i, h in enumerate(headers):
        nh = norm_header(h)
        if "pts" in nh and "pts" not in idx: idx["pts"] = i
        if re.search(r"\breb\b", nh) and "reb" not in idx: idx["reb"] = i
        if re.search(r"\bast\b", nh) and "ast" not in idx: idx["ast"] = i
        if re.search(r"\bstl\b", nh) and "stl" not in idx: idx["stl"] = i
        if re.search(r"\bblk\b", nh) and "blk" not in idx: idx["blk"] = i
    if not idx:
        logdbg("HEAD MISSING")
    else:
        logdbg("HEAD OK", idx)
    return idx

def extract_team_block(soup: BeautifulSoup, team_ru: str):
    # 1) —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ ¬´–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–≥—Ä–æ–∫–æ–≤. {–ö–æ–º–∞–Ω–¥–∞}¬ª
    for h in soup.find_all(["h2","h3","h4"]):
        txt = h.get_text(" ", strip=True)
        if "—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–≥—Ä–æ–∫–æ–≤" in txt.lower() and team_ru.lower() in txt.lower():
            tbl = h.find_next("table")
            if tbl: return tbl
    # 2) –±–ª–∏–∂–∞–π—à–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø–æ—Å–ª–µ –ª—é–±–æ–≥–æ ¬´–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–≥—Ä–æ–∫–æ–≤¬ª
    for h in soup.find_all(["h2","h3","h4"]):
        if "—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–≥—Ä–æ–∫–æ–≤" in h.get_text(" ", strip=True).lower():
            tbl = h.find_next("table")
            if tbl: return tbl
    return None

def parse_players_from_table(tbl) -> tuple[list[dict], bool]:
    idx = map_header_indices(tbl)
    if not idx:
        return [], False
    tbody = tbl.find("tbody") or tbl
    players = []
    for tr in tbody.find_all("tr"):
        cells = tr.find_all(["td","th"])
        if not cells: continue
        # –∏–º—è ‚Äî –ø–µ—Ä–≤–∞—è –Ω–µ-—á–∏—Å–ª–æ–≤–∞—è —è—á–µ–π–∫–∞ –≤ –ø–µ—Ä–≤—ã—Ö 3
        name = ""
        for j in range(min(3, len(cells))):
            cand = cells[j].get_text(" ", strip=True)
            if re.fullmatch(r"[#‚Ññ]?\d{1,3}", cand):
                continue
            a = cells[j].find("a")
            name = (a.get_text(" ", strip=True) if a else cand).strip()
            break
        if not name or name.isdigit():
            continue
        def val(key):
            i = idx.get(key, -1)
            if i < 0 or i >= len(cells): return 0
            raw = cells[i].get_text(" ", strip=True)
            m = re.search(r"-?\d+", raw)
            return int(m.group(0)) if m else 0
        players.append({
            "name_ru": name,
            "pts": val("pts"), "reb": val("reb"), "ast": val("ast"),
            "stl": val("stl"), "blk": val("blk"),
        })
    return players, True

def parse_sports_match(url: str) -> dict | None:
    r = S.get(url, timeout=25)
    if r.status_code != 200: return None
    soup = BeautifulSoup(r.text, "html.parser")

    a_abbr = abbr_from_url(url, 0); b_abbr = abbr_from_url(url, 1)
    if not (a_abbr and b_abbr): return None
    nameA = TEAM_RU.get(a_abbr, a_abbr); nameB = TEAM_RU.get(b_abbr, b_abbr)

    scoreA = scoreB = 0
    ot_flag = detect_ot_by_periods(soup)

    tblA = extract_team_block(soup, nameA)
    tblB = extract_team_block(soup, nameB)
    playersA, okA = ([], False)
    playersB, okB = ([], False)
    if tblA:
        playersA, okA = parse_players_from_table(tblA)
        # totals ‚Üí –æ—á–∫–∏ –∫–æ–º–∞–Ω–¥—ã
        for tr in (tblA.find("tbody") or tblA).find_all("tr"):
            t0 = tr.find(["th","td"])
            if t0 and re.search(r"^(–∏—Ç–æ–≥–æ|–≤—Å–µ–≥–æ)\s*$", t0.get_text(" ", strip=True), re.I):
                idx = map_header_indices(tblA)
                if "pts" in idx:
                    tds = tr.find_all(["td","th"])
                    if idx["pts"] < len(tds):
                        m = re.search(r"\d+", tds[idx["pts"]].get_text(" ", strip=True))
                        if m: scoreA = int(m.group(0))
                break
    if tblB:
        playersB, okB = parse_players_from_table(tblB)
        for tr in (tblB.find("tbody") or tblB).find_all("tr"):
            t0 = tr.find(["th","td"])
            if t0 and re.search(r"^(–∏—Ç–æ–≥–æ|–≤—Å–µ–≥–æ)\s*$", t0.get_text(" ", strip=True), re.I):
                idx = map_header_indices(tblB)
                if "pts" in idx:
                    tds = tr.find_all(["td","th"])
                    if idx["pts"] < len(tds):
                        m = re.search(r"\d+", tds[idx["pts"]].get_text(" ", strip=True))
                        if m: scoreB = int(m.group(0))
                break

    if not (scoreA and scoreB):
        # –±—ç–∫–∞–ø: –æ–±—â–∏–π —Å—á—ë—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        txt = soup.get_text(" ", strip=True)
        m = re.search(r"\b(\d{1,3})\s*:\s*(\d{1,3})\b", txt)
        if m:
            scoreA = scoreA or int(m.group(1))
            scoreB = scoreB or int(m.group(2))

    logdbg("SPORTS TEAMS", nameA, nameB, "SCORE", scoreA, scoreB, "A_rows", len(playersA), "B_rows", len(playersB))

    return {
        "url": url,
        "teams": [
            {"abbr": a_abbr, "name_ru": nameA, "score": scoreA, "players": playersA if okA else []},
            {"abbr": b_abbr, "name_ru": nameB, "score": scoreB, "players": playersB if okB else []},
        ],
        "ot": bool(ot_flag),
    }

# ================== ESPN FALLBACK ==================
def espn_scoreboard(d: date) -> list[dict]:
    j = _get_json(ESPN_SB.format(ymd=d.strftime("%Y%m%d")))
    return j.get("events") or []

def espn_find_event_for_pair(d: date, ab1: str, ab2: str):
    need = {ab1, ab2}
    for ev in espn_scoreboard(d):
        comp = (ev.get("competitions") or [{}])[0]
        abbrs=set(); mapping={}
        for c in (comp.get("competitors") or []):
            t=c.get("team") or {}
            ab = norm_abbr(t.get("abbreviation") or "")
            mapping[str(t.get("id") or "")]=ab
            abbrs.add(ab)
        if need == abbrs:
            return ev, mapping
    return None, {}

def espn_box_players(event_id: str) -> dict[str, list[dict]]:
    j = _get_json(ESPN_BOX.format(eid=event_id))
    out={}
    for t in (j.get("players") or []):
        team = t.get("team") or {}
        tid = str(team.get("id") or "")
        arr=[]
        for grp in (t.get("statistics") or []):
            for a in (grp.get("athletes") or []):
                ath = a.get("athlete") or {}
                nm  = (ath.get("displayName") or "").strip()
                stats={}
                for k,v in (a.get("stats") or {}).items(): stats[k.lower()] = v
                for k,v in (ath.get("stats") or {}).items(): stats.setdefault(k.lower(), v)
                def iget(*keys, default=0):
                    for k in keys:
                        if k in stats:
                            try: return int(stats[k])
                            except:
                                try: return int(float(stats[k]))
                                except: pass
                    return default
                pts=iget("points","pts"); reb=iget("rebounds","reb","reboundstotal")
                ast=iget("assists","ast"); stl=iget("steals","stl"); blk=iget("blocks","blk")
                if any([pts,reb,ast,stl,blk]):
                    arr.append({"name_ru": nm, "pts": pts, "reb": reb, "ast": ast, "stl": stl, "blk": blk, "_src":"espn"})
        merged={}
        for p in arr:
            key=p["name_ru"]
            if key not in merged: merged[key]=p
            else:
                m=merged[key]
                for k in ("pts","reb","ast","stl","blk"): m[k]=max(m[k], p[k])
        out[tid]=list(merged.values())
    return out

# ================== NAMES (Sports.ru) ==================
SPORTS_RU = "https://www.sports.ru"
SRU_PERSON = SPORTS_RU + "/basketball/person/"
SRU_PLAYER = SPORTS_RU + "/basketball/player/"
SRU_SEARCH = SPORTS_RU + "/search/?q="

def _slugify(first_last: str) -> str:
    base=re.sub(r"[^a-z0-9]+","-", first_last.lower()).strip("-")
    return base

def _sru_profile(first: str, last: str) -> str | None:
    slug=_slugify(f"{first} {last}")
    for root in (SRU_PERSON, SRU_PLAYER):
        url=root+slug+"/"
        try:
            r=S.get(url, timeout=12)
            if r.status_code==200 and ("/basketball/person/" in r.url or "/basketball/player/" in r.url):
                return url
        except Exception:
            pass
    return None

def _sru_name_from(url: str) -> str | None:
    try:
        r=S.get(url, timeout=12)
        if r.status_code!=200: return None
        soup=BeautifulSoup(r.text,"html.parser")
        h=soup.find(["h1","h2"])
        full=h.get_text(" ", strip=True) if h else ""
        full=" ".join(full.split())
        return full or None
    except Exception:
        return None

def _sru_search(first: str, last: str) -> str | None:
    try:
        q=quote_plus(f"{first} {last}")
        r=S.get(SRU_SEARCH+q, timeout=12)
        if r.status_code!=200: return None
        soup=BeautifulSoup(r.text,"html.parser")
        a=soup.select_one('a[href*="/basketball/person/"]') or soup.select_one('a[href*="/basketball/player/"]')
        if not a or not a.get("href"): return None
        href=a["href"]; 
        if href.startswith("/"): href=SPORTS_RU+href
        return _sru_name_from(href)
    except Exception:
        return None

def to_initials_ru(full_or_en: str) -> str:
    parts=[p for p in re.split(r"\s+", (full_or_en or "").strip()) if p]
    if not parts: return full_or_en or ""
    if len(parts)==1: return parts[0]
    first=parts[0]; last=parts[-1]
    if last.lower() in {"jr.","jr","sr.","sr"} and len(parts)>=3:
        last=parts[-2]+" "+parts[-1]
    return f"{first[0]}. {last}"

def normalize_name_ru(p: dict) -> str:
    # –£–∂–µ —Ä—É—Å—Å–∫–æ–µ –∏–º—è?
    if p.get("_src") != "espn":
        return to_initials_ru(p.get("name_ru",""))
    full = p.get("name_ru","")
    parts=[x for x in full.split() if x]
    if len(parts)>=2:
        first, last = parts[0], " ".join(parts[1:])
        url=_sru_profile(first, last) or _sru_search(first, last)
        if url:
            nm=_sru_name_from(url)
            if nm:
                parts_ru=[w for w in nm.split() if w]
                if len(parts_ru)>=2:
                    return f"{parts_ru[0][0]}. {parts_ru[-1]}"
                return nm
    return to_initials_ru(full)

# ================== PICK / FORMAT PLAYERS ==================
def is_dd(p: dict) -> bool: 
    return sum(v>=10 for v in [p["pts"],p["reb"],p["ast"],p["stl"],p["blk"]])>=2
def second_ok(p: dict) -> bool:
    return p["pts"]>=20 or is_dd(p) or p["stl"]>=6 or p["blk"]>=6
def score_key(p: dict): return (p["pts"], p["reb"]+p["ast"], p["stl"]+p["blk"])

def pick_team_players(abbr: str, rows: list[dict]) -> list[tuple[dict,bool,bool]]:
    if not rows: return []
    rows = sorted(rows, key=score_key, reverse=True)
    special=None
    key_tail = "demin" if abbr=="BKN" else ("goldin" if abbr=="MIA" else None)
    if key_tail:
        for p in rows:
            nm=(p.get("name_ru") or "").lower()
            if key_tail in nm or "–¥—ë–º–∏–Ω" in nm or "–≥–æ–ª–¥–∏–Ω" in nm:
                special=p; break
    out=[]
    top=rows[0]
    if special and special is top:
        out.append((special, True, True))
    elif special:
        out.append((top, False, False)); out.append((special, True, True))
    else:
        out.append((top, False, False))
        for p in rows[1:]:
            if second_ok(p): out.append((p, False, False)); break
    return out[:2]

def sp(s: str) -> str: return f'<span class="tg-spoiler">{s}</span>'
SEP = "‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì"

def fmt_player_line(p: dict, bold=False, special=False) -> str:
    name = normalize_name_ru(p)
    if bold: name = f"<b>{name}</b>"
    if special:
        stats=[("pts",p["pts"]),("reb",p["reb"]),("ast",p["ast"]),("stl",p["stl"]),("blk",p["blk"])]
        stats=[(k,v) for k,v in stats if v>0]
        stats.sort(key=lambda kv: kv[1], reverse=True)
        stats=stats[:3]
        def f(lbl,val):
            if lbl=="pts": return f"{val} {ru_plural(val, ('–æ—á–∫–æ','–æ—á–∫–∞','–æ—á–∫–æ–≤'))}"
            if lbl=="reb": return f"{val} {ru_plural(val, ('–ø–æ–¥–±–æ—Ä','–ø–æ–¥–±–æ—Ä–∞','–ø–æ–¥–±–æ—Ä–æ–≤'))}"
            if lbl=="ast": return f"{val} {ru_plural(val, ('–ø–µ—Ä–µ–¥–∞—á–∞','–ø–µ—Ä–µ–¥–∞—á–∏','–ø–µ—Ä–µ–¥–∞—á'))}"
            if lbl=="stl": return f"{val} {ru_plural(val, ('–ø–µ—Ä–µ—Ö–≤–∞—Ç','–ø–µ—Ä–µ—Ö–≤–∞—Ç–∞','–ø–µ—Ä–µ—Ö–≤–∞—Ç–æ–≤'))}"
            return f"{val} {ru_plural(val, ('–±–ª–æ–∫-—à–æ—Ç','–±–ª–æ–∫-—à–æ—Ç–∞','–±–ª–æ–∫-—à–æ—Ç–æ–≤'))}"
        line = f"{name}: " + ", ".join(f(k,v) for k,v in stats)
    else:
        chunks=[f"{p['pts']} {ru_plural(p['pts'], ('–æ—á–∫–æ','–æ—á–∫–∞','–æ—á–∫–æ–≤'))}"]
        if p["reb"]>=5: chunks.append(f"{p['reb']} {ru_plural(p['reb'], ('–ø–æ–¥–±–æ—Ä','–ø–æ–¥–±–æ—Ä–∞','–ø–æ–¥–±–æ—Ä–æ–≤'))}")
        if p["ast"]>=5: chunks.append(f"{p['ast']} {ru_plural(p['ast'], ('–ø–µ—Ä–µ–¥–∞—á–∞','–ø–µ—Ä–µ–¥–∞—á–∏','–ø–µ—Ä–µ–¥–∞—á'))}")
        if p["stl"]>=4: chunks.append(f"{p['stl']} {ru_plural(p['stl'], ('–ø–µ—Ä–µ—Ö–≤–∞—Ç','–ø–µ—Ä–µ—Ö–≤–∞—Ç–∞','–ø–µ—Ä–µ—Ö–≤–∞—Ç–æ–≤'))}")
        if p["blk"]>=4: chunks.append(f"{p['blk']} {ru_plural(p['blk'], ('–±–ª–æ–∫-—à–æ—Ç','–±–ª–æ–∫-—à–æ—Ç–∞','–±–ª–æ–∫-—à–æ—Ç–æ–≤'))}")
        line = f"{name}: " + ", ".join(chunks)
    if (p["pts"]>=35) or (p["reb"]>=15) or (p["ast"]>=12) or (p["stl"]>=5) or (p["blk"]>=5):
        line += " üî•"
    return sp(line)

def build_block(game: dict) -> str:
    t1, t2 = game["teams"][0], game["teams"][1]
    name1, name2 = t1["name_ru"], t2["name_ru"]
    ab1, ab2 = t1["abbr"], t2["abbr"]
    e1, e2 = team_emoji(ab1), team_emoji(ab2)
    a_win = t1["score"] > t2["score"]; b_win = t2["score"] > t1["score"]

    ot_tag = " (–û–¢)" if game.get("ot") else ""

    score1_txt = f"<b>{t1['score']}</b>" if a_win else f"{t1['score']}"
    score2_txt = f"<b>{t2['score']}</b>" if b_win else f"{t2['score']}"

    head = (
        f"{e1} {name1}: {sp(score1_txt)}\n"
        f"{e2} {name2}: {sp(score2_txt)}{ot_tag}\n\n"
    )

    lines=[]
    p1 = pick_team_players(ab1, t1.get("players") or [])
    p2 = pick_team_players(ab2, t2.get("players") or [])
    for p,bold,spec in p1:
        lines.append(fmt_player_line(p, bold=bold, special=spec))
    if p1 and p2: lines.append("")
    for p,bold,spec in p2:
        lines.append(fmt_player_line(p, bold=bold, special=spec))
    return head + ("\n".join(lines) if lines else "")

# ================== ENRICH (ESPN) ==================
def enrich_with_espn(game: dict, d: date):
    ab1 = game["teams"][0]["abbr"]; ab2 = game["teams"][1]["abbr"]
    ev, id2abbr = espn_find_event_for_pair(d, ab1, ab2)
    if not ev:
        logdbg("ESPN fallback: event not found for", ab1, ab2)
        return

    # –∑–∞–ø–æ–ª–Ω–∏–º –∏–≥—Ä–æ–∫–æ–≤, –µ—Å–ª–∏ –ø—É—Å—Ç–æ
    need_a = not game["teams"][0]["players"]
    need_b = not game["teams"][1]["players"]
    if need_a or need_b:
        by_tid = espn_box_players(ev.get("id", ""))
        for tid, lst in by_tid.items():
            ab = id2abbr.get(tid)
            if ab == ab1 and need_a:
                game["teams"][0]["players"] = lst
            elif ab == ab2 and need_b:
                game["teams"][1]["players"] = lst

    # –µ—Å–ª–∏ —Å—á—ë—Ç –Ω–µ —Å—á–∏—Ç–∞–ª—Å—è ‚Äî –±–µ—Ä—ë–º –∏–∑ ESPN; —Ç–∞–∫–∂–µ –æ—Ç–º–µ—Ç–∏–º –û–¢ –ø–æ —á–∏—Å–ª—É –ø–µ—Ä–∏–æ–¥–æ–≤
    try:
        comp = (ev.get("competitions") or [{}])[0]
        comps = comp.get("competitors") or []
        home = next(c for c in comps if c.get("homeAway")=="home")
        away = next(c for c in comps if c.get("homeAway")=="away")
        th, ta = home.get("team") or {}, away.get("team") or {}
        h_ab = norm_abbr(th.get("abbreviation") or "")
        a_ab = norm_abbr(ta.get("abbreviation") or "")
        def as_int(v): 
            try: return int(float(v))
            except: return 0
        h_sc = as_int(home.get("score", 0)); a_sc = as_int(away.get("score", 0))
        status = (ev.get("status") or {}).get("type") or {}
        period = int(status.get("period") or 0)
        ot = (period > 4)

        # –º–∞–ø–ø–∏–Ω–≥ –ø–æ –Ω–∞—à–∏–º —Å—Ç–æ—Ä–æ–Ω–∞–º
        if h_ab == ab1 and a_ab == ab2:
            if game["teams"][0]["score"] == 0: game["teams"][0]["score"] = h_sc
            if game["teams"][1]["score"] == 0: game["teams"][1]["score"] = a_sc
        elif h_ab == ab2 and a_ab == ab1:
            if game["teams"][1]["score"] == 0: game["teams"][1]["score"] = h_sc
            if game["teams"][0]["score"] == 0: game["teams"][0]["score"] = a_sc
        if ot: game["ot"] = True
    except Exception:
        pass

# ================== POST BUILD ==================
def pick_report_day() -> date:
    d_today = et_today()
    today_cnt = len(fetch_day_links(d_today))
    if today_cnt > 0:
        logdbg("DAY PICK", d_today, "(today)")
        return d_today
    d_yest = d_today - timedelta(days=1)
    logdbg("DAY PICK", d_yest, "(yesterday fallback)")
    return d_yest

def build_post(d: date) -> str:
    links = fetch_day_links(d)
    games=[]
    for u in links:
        try:
            g = parse_sports_match(u)
            if g: games.append(g)
        except Exception as e:
            logdbg("PARSE ERROR", u, repr(e))

    # –î–æ—Ç—è–≥–∏–≤–∞–µ–º –∏–≥—Ä–æ–∫–æ–≤/—Å—á—ë—Ç —á–µ—Ä–µ–∑ ESPN —Ç–∞–º, –≥–¥–µ –Ω–µ —Ä–∞–∑–æ–±—Ä–∞–ª–∏ Sports.ru
    for g in games:
        enrich_with_espn(g, d)

    n=len(games)
    title = (
        f"–ù–ë–ê ‚Ä¢ {ru_date(d)} ‚Ä¢ {n} {ru_plural(n, ('–º–∞—Ç—á','–º–∞—Ç—á–∞','–º–∞—Ç—á–µ–π'))}\n"
        "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞–¥—ë–∂–Ω–æ —Å–ø—Ä—è—Ç–∞–Ω—ã üëá\n"
        "‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì\n\n"
    )
    if n==0: return title.rstrip()
    blocks=[]
    for i,g in enumerate(games):
        blocks.append(build_block(g))
        if i+1 < n: blocks.append("\n‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì\n\n")
    return (title + "".join(blocks)).strip()

# ================== TELEGRAM ==================
def tg_send(text: str):
    if not (BOT_TOKEN and CHAT_ID):
        raise RuntimeError("TELEGRAM_BOT_TOKEN / TELEGRAM_CHAT_ID –Ω–µ –∑–∞–¥–∞–Ω—ã")
    url=f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    r=S.post(url, json={
        "chat_id": CHAT_ID,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": True,
    }, timeout=25)
    if r.status_code!=200:
        raise RuntimeError(f"Telegram error {r.status_code}: {r.text}")

# ================== MAIN ==================
if __name__ == "__main__":
    try:
        day = pick_report_day()
        post = build_post(day)
        tg_send(post)
        print("OK")
    except Exception as e:
        print("ERROR:", repr(e), file=sys.stderr)
        sys.exit(1)
