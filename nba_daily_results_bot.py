#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
NBA Daily Results ‚Üí Telegram (RU) ‚Äî Sports.ru only

–ß—Ç–æ –¥–µ–ª–∞–µ—Ç:
‚Ä¢ –ù–∞—Ö–æ–¥–∏—Ç –º–∞—Ç—á–∏ –¥–Ω—è –Ω–∞ https://www.sports.ru/stat/basketball/center/end/YYYY/MM/DD.html
‚Ä¢ –û—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ –ù–ë–ê (–æ–±–∞ —É—á–∞—Å—Ç–Ω–∏–∫–∞ slugs –º–∞–ø—è—Ç—Å—è –≤ –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã –ù–ë–ê).
‚Ä¢ –í –∫–∞–∂–¥–æ–π –∏–≥—Ä–µ –ø–∞—Ä—Å–∏—Ç <h3> ¬´‚Ä¶ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–≥—Ä–æ–∫–æ–≤¬ª –∏ –±–ª–∏–∂–∞–π—à—É—é —Ç–∞–±–ª–∏—Ü—É: –∏–≥—Ä–æ–∫–æ–≤ + ¬´–ò—Ç–æ–≥–æ¬ª.
‚Ä¢ –°–æ–±–∏—Ä–∞–µ—Ç –µ–¥–∏–Ω—ã–π –ø–æ—Å—Ç —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –ø—Ä–∞–≤–∏–ª–∞–º–∏ –æ—Ç–±–æ—Ä–∞ –∏–≥—Ä–æ–∫–æ–≤ –∏ —Å–ø–æ–π–ª–µ—Ä–∞–º–∏.

–í–∞–∂–Ω–æ:
‚Ä¢ –ï—Å–ª–∏ ¬´—Å–µ–≥–æ–¥–Ω—è –ø–æ ET¬ª –¥–∞—ë—Ç –º–∞–ª–æ –º–∞—Ç—á–µ–π, –±–µ—Ä—ë–º ¬´–≤—á–µ—Ä–∞ –ø–æ ET¬ª ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –¥–µ–Ω—å, –≥–¥–µ –º–∞—Ç—á–µ–π –±–æ–ª—å—à–µ.
‚Ä¢ –õ–æ–≥–∏ –≤–∫–ª—é—á–∞—é—Ç—Å—è –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è DEBUG_NBA=1
"""

import os, sys, re, json, time
from datetime import datetime, timedelta, date
from zoneinfo import ZoneInfo
from urllib.parse import urljoin

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from bs4 import BeautifulSoup

# ========= ENV & LOG =========
BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "").strip()
CHAT_ID   = os.getenv("TELEGRAM_CHAT_ID", "").strip()
DEBUG     = os.getenv("DEBUG_NBA", "").strip() not in {"", "0", "false", "False"}

def logdbg(*a):
    if DEBUG:
        print("[DBG]", *a, file=sys.stderr)

# ========= DATE HELPERS =========
def et_today() -> date:
    return datetime.now(ZoneInfo("America/New_York")).date()

def pick_best_report_date() -> date:
    """–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º ¬´—Å–µ–≥–æ–¥–Ω—è –ø–æ ET¬ª –∏ ¬´–≤—á–µ—Ä–∞ –ø–æ ET¬ª –ø–æ —á–∏—Å–ª—É —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã—Ö –º–∞—Ç—á–µ–π ‚Äî –±–µ—Ä—ë–º —Ç–æ—Ç, –≥–¥–µ –±–æ–ª—å—à–µ."""
    d_today = et_today()
    d_yest  = d_today - timedelta(days=1)
    n_today = count_games_for_day(d_today)
    n_yest  = count_games_for_day(d_yest)
    logdbg(f"DAY CANDIDATES ET today={d_today}({n_today}) / yest={d_yest}({n_yest})")
    return d_today if n_today >= n_yest else d_yest

RU_MONTHS = {1:"—è–Ω–≤–∞—Ä—è",2:"—Ñ–µ–≤—Ä–∞–ª—è",3:"–º–∞—Ä—Ç–∞",4:"–∞–ø—Ä–µ–ª—è",5:"–º–∞—è",6:"–∏—é–Ω—è",
             7:"–∏—é–ª—è",8:"–∞–≤–≥—É—Å—Ç–∞",9:"—Å–µ–Ω—Ç—è–±—Ä—è",10:"–æ–∫—Ç—è–±—Ä—è",11:"–Ω–æ—è–±—Ä—è",12:"–¥–µ–∫–∞–±—Ä—è"}
def ru_date(d: date) -> str: return f"{d.day} {RU_MONTHS[d.month]}"
def ru_plural(n: int, forms: tuple[str,str,str]) -> str:
    n = abs(int(n)) % 100; n1 = n % 10
    if 11 <= n <= 19: return forms[2]
    if 2 <= n1 <= 4:  return forms[1]
    if n1 == 1:      return forms[0]
    return forms[2]

# ========= HTTP =========
def make_session():
    s = requests.Session()
    r = Retry(total=6, connect=6, read=6, backoff_factor=0.7,
              status_forcelist=[429,500,502,503,504], allowed_methods=["GET"])
    s.mount("https://", HTTPAdapter(max_retries=r))
    s.headers.update({
        "User-Agent": "NBA-DailyResultsBot/5.0 (sports.ru)",
        "Accept-Language": "ru,en;q=0.7",
    })
    return s
S = make_session()

# ========= CONSTANTS / MAPS =========
DAY_URL_TMPL = "https://www.sports.ru/stat/basketball/center/end/{y:04d}/{m:02d}/{d:02d}.html"
MATCH_PREFIX = "https://www.sports.ru/basketball/match/"

SLUG2ABBR = {
    "atlanta-hawks":"ATL","boston-celtics":"BOS","brooklyn-nets":"BKN","charlotte-hornets":"CHA",
    "chicago-bulls":"CHI","cleveland-cavaliers":"CLE","dallas-mavericks":"DAL","denver-nuggets":"DEN",
    "detroit-pistons":"DET","golden-state-warriors":"GSW","houston-rockets":"HOU","indiana-pacers":"IND",
    "los-angeles-clippers":"LAC","los-angeles-lakers":"LAL","memphis-grizzlies":"MEM","miami-heat":"MIA",
    "milwaukee-bucks":"MIL","minnesota-timberwolves":"MIN","new-orleans-pelicans":"NOP","new-york-knicks":"NYK",
    "oklahoma-city-thunder":"OKC","orlando-magic":"ORL","philadelphia-76ers":"PHI","phoenix-suns":"PHX",
    "portland-trail-blazers":"POR","sacramento-kings":"SAC","san-antonio-spurs":"SAS","toronto-raptors":"TOR",
    "utah-jazz":"UTA","washington-wizards":"WAS",
}
TEAM_RU = {
    "ATL":"–ê—Ç–ª–∞–Ω—Ç–∞","BOS":"–ë–æ—Å—Ç–æ–Ω","BKN":"–ë—Ä—É–∫–ª–∏–Ω","CHA":"–®–∞—Ä–ª–æ—Ç—Ç","CHI":"–ß–∏–∫–∞–≥–æ","CLE":"–ö–ª–∏–≤–ª–µ–Ω–¥",
    "DAL":"–î–∞–ª–ª–∞—Å","DEN":"–î–µ–Ω–≤–µ—Ä","DET":"–î–µ—Ç—Ä–æ–π—Ç","GSW":"–ì–æ–ª–¥–µ–Ω –°—Ç—ç–π—Ç","HOU":"–•—å—é—Å—Ç–æ–Ω","IND":"–ò–Ω–¥–∏–∞–Ω–∞",
    "LAC":"–ö–ª–∏–ø–ø–µ—Ä—Å","LAL":"–õ–µ–π–∫–µ—Ä—Å","MEM":"–ú–µ–º—Ñ–∏—Å","MIA":"–ú–∞–π–∞–º–∏","MIL":"–ú–∏–ª—É–æ–∫–∏","MIN":"–ú–∏–Ω–Ω–µ—Å–æ—Ç–∞",
    "NOP":"–ù–æ–≤—ã–π –û—Ä–ª–µ–∞–Ω","NYK":"–ù—å—é-–ô–æ—Ä–∫","OKC":"–û–∫–ª–∞—Ö–æ–º–∞-–°–∏—Ç–∏","ORL":"–û—Ä–ª–∞–Ω–¥–æ","PHI":"–§–∏–ª–∞–¥–µ–ª—å—Ñ–∏—è",
    "PHX":"–§–∏–Ω–∏–∫—Å","POR":"–ü–æ—Ä—Ç–ª–µ–Ω–¥","SAC":"–°–∞–∫—Ä–∞–º–µ–Ω—Ç–æ","SAS":"–°–∞–Ω-–ê–Ω—Ç–æ–Ω–∏–æ","TOR":"–¢–æ—Ä–æ–Ω—Ç–æ","UTA":"–Æ—Ç–∞","WAS":"–í–∞—à–∏–Ω–≥—Ç–æ–Ω",
}

def team_emoji(_abbr: str) -> str:
    # –¢–µ–∫—Å—Ç–æ–≤—ã–π –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä (–∫–∞—Å—Ç–æ–º-—ç–º–æ–¥–∑–∏-–≤–µ—Ä—Å–∏–∏ ‚Äî –æ—Ç–¥–µ–ª—å–Ω–æ).
    return "üèÄ"

# ========= DAY LINKS =========
def fetch_day_links(d: date) -> list[str]:
    url = DAY_URL_TMPL.format(y=d.year, m=d.month, d=d.day)
    r = S.get(url, timeout=25)
    if r.status_code != 200:
        logdbg("SPORTS DAY URL FAIL", url, r.status_code)
        return []
    logdbg("SPORTS DAY URL", url, "OK")
    soup = BeautifulSoup(r.text, "html.parser")
    links = []
    for a in soup.find_all("a", href=True):
        h = a["href"]
        if not (h.startswith("/basketball/match/") or h.startswith(MATCH_PREFIX)):
            continue
        if "/live/" in h:
            continue
        full = urljoin("https://www.sports.ru", h)
        if "vs" not in full:
            continue
        # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–ª—ç—à –∏ –±–µ–∑ —è–∫–æ—Ä–µ–π
        full = full.split("#", 1)[0]
        if not full.endswith("/"):
            full += "/"
        links.append(full)
    # dedup
    out, seen = [], set()
    for u in links:
        if u not in seen:
            out.append(u); seen.add(u)
    logdbg("SPORTS LINKS", len(out))
    return out

def count_games_for_day(d: date) -> int:
    cnt = 0
    for u in fetch_day_links(d):
        a = abbr_from_url(u, 0)
        b = abbr_from_url(u, 1)
        if a and b and a in TEAM_RU and b in TEAM_RU:
            cnt += 1
    return cnt

# ========= MATCH PARSER =========
HEAD_RE = re.compile(r"\s*(.+?)\.\s*—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–≥—Ä–æ–∫–æ–≤\s*$", re.IGNORECASE)

# –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∫–æ–ª–æ–Ω–∫–∏
def norm_col(text: str) -> str:
    t = re.sub(r"\s+", "", (text or "").lower())
    t = t.replace("–æ—á–∫–∏", "–æ—á").replace("–ø–µ—Ä–µ–¥–∞—á–∏", "–ø–µ—Ä–µ–¥").replace("–ø–æ–¥–±–æ—Ä—ã", "–ø–æ–¥–±–æ—Ä")
    t = t.replace("–ø–µ—Ä–µ—Ö–≤–∞—Ç—ã", "–ø–µ—Ä–µ—Ö").replace("–±–ª–æ–∫-—à–æ—Ç—ã", "–±–ª–æ–∫—à–æ—Ç—ã").replace("–±–ª–æ–∫—à–æ—Ç", "–±–ª–æ–∫—à–æ—Ç—ã")
    return t

# —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∞–º
def col_metric(t: str) -> str | None:
    if t in {"–æ—á","–æ—á–∫–∏","pts"}: return "pts"
    if t in {"–ø–æ–¥–±–æ—Ä","–ø–æ–¥–±","reb"}: return "reb"
    if t in {"–ø–µ—Ä–µ–¥","–ø–µ—Ä–µ–¥–∞—á–∏","ast","–ø–∞—Å"}: return "ast"
    if t in {"–ø–µ—Ä–µ—Ö","stl"}: return "stl"
    if t in {"–±–ª–æ–∫—à–æ—Ç—ã","blk","–±—à","–±–ª–æ–∫"}: return "blk"
    return None

def _int_first(text: str) -> int:
    m = re.search(r"-?\d+", text or "")
    return int(m.group(0)) if m else 0

def abbr_from_url(url: str, side: int) -> str | None:
    m = re.search(r"/basketball/match/([a-z0-9\-]+)-vs-([a-z0-9\-]+)/", url)
    if not m: return None
    slug = m.group(1 + side)
    return SLUG2ABBR.get(slug)

def parse_stats_table(team_header_h3) -> tuple[list[dict], int]:
    """–ò–∑ <h3> ‚Ä¶—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–≥—Ä–æ–∫–æ–≤ ‚Üí –ø–∞—Ä—Å–∏–º –±–ª–∏–∂–∞–π—à—É—é —Ç–∞–±–ª–∏—Ü—É, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º (players, team_total_pts)."""
    tbl = team_header_h3.find_next("table")
    if not tbl:
        return [], 0

    # –Ω–∞–π–¥—ë–º —Å—Ç—Ä–æ–∫—É –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ (thead –∏–ª–∏ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ —Å –±—É–∫–≤–∞–º–∏)
    header_cells = None
    thead = tbl.find("thead")
    if thead:
        # –±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É thead ‚Äî —á–∞—Å—Ç–æ —Ç–∞–º –ø–æ–¥–ø–∏—Å–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π
        rows = thead.find_all("tr")
        if rows:
            header_cells = [c.get_text(" ", strip=True) for c in rows[-1].find_all(["th","td"])]
    if not header_cells:
        for tr in tbl.find_all("tr"):
            tds = tr.find_all(["th","td"])
            if not tds: 
                continue
            if any(re.search(r"[A-Za-z–ê-–Ø–∞-—è]", c.get_text()) for c in tds):
                header_cells = [c.get_text(" ", strip=True) for c in tds]
                break
    if not header_cells:
        return [], 0

    idx_map = {}
    for idx, htxt in enumerate(header_cells):
        m = col_metric(norm_col(htxt))
        if m and m not in idx_map:
            idx_map[m] = idx

    players = []
    team_pts = 0

    tbody = tbl.find("tbody") or tbl
    for tr in tbody.find_all("tr"):
        tds = tr.find_all("td")
        if not tds:
            continue
        first_txt = tds[0].get_text(" ", strip=True)

        # ¬´–ò—Ç–æ–≥–æ¬ª ‚Äî –∫–æ–º–∞–Ω–¥–∞
        if re.search(r"^(–∏—Ç–æ–≥–æ|–≤—Å–µ–≥–æ)\s*$", first_txt, flags=re.IGNORECASE):
            if "pts" in idx_map and idx_map["pts"] < len(tds):
                team_pts = _int_first(tds[idx_map["pts"]].get_text(" ", strip=True))
            continue

        # –ò–≥—Ä–æ–∫ ‚Äî –∏—â–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
        name_cell = tds[0]
        a = name_cell.find("a")
        if not a:
            # –∏–Ω–æ–≥–¥–∞ –±–µ–∑ <a>, –Ω–æ —Å —Ç–µ–∫—Å—Ç–æ–º
            name_ru = first_txt.strip()
        else:
            name_ru = a.get_text(" ", strip=True).strip()
        if not name_ru:
            continue

        def val(metric):
            if metric not in idx_map or idx_map[metric] >= len(tds):
                return 0
            return _int_first(tds[idx_map[metric]].get_text(" ", strip=True))

        p = {
            "name_ru": name_ru,
            "pts": val("pts"),
            "reb": val("reb"),
            "ast": val("ast"),
            "stl": val("stl"),
            "blk": val("blk"),
        }
        if any(p[k] for k in ("pts","reb","ast","stl","blk")):
            players.append(p)

    return players, team_pts

def detect_ot(soup: BeautifulSoup) -> bool:
    # –ø—Ä–æ–±—É–µ–º –ø–æ —Ç–∞–±–ª–∏—Ü–µ ¬´–ü–æ –ø–µ—Ä–∏–æ–¥–∞–º¬ª
    for h3 in soup.find_all("h3"):
        txt = (h3.get_text(" ", strip=True) or "").lower()
        if "–ø–µ—Ä–∏–æ–¥" in txt:
            tbl = h3.find_next("table")
            if not tbl:
                continue
            row = tbl.find("tr")
            if not row:
                continue
            s = row.get_text(" ", strip=True)
            pairs = re.findall(r"\b\d{1,2}\s*:\s*\d{1,2}\b", s)
            if len(pairs) > 4:
                return True
    # fallback ‚Äî –∏—â–µ–º ¬´–û–¢¬ª –≤ —Ç–µ–∫—Å—Ç–µ
    txt = soup.get_text(" ", strip=True)
    return bool(re.search(r"\b–û–¢\b|–û–≤–µ—Ä—Ç–∞–π–º", txt, flags=re.IGNORECASE))

def parse_sports_match(url: str) -> dict | None:
    a_abbr = abbr_from_url(url, 0)
    b_abbr = abbr_from_url(url, 1)
    if not (a_abbr and b_abbr and a_abbr in TEAM_RU and b_abbr in TEAM_RU):
        return None  # –Ω–µ –ù–ë–ê

    r = S.get(url, timeout=25)
    if r.status_code != 200:
        logdbg("PARSE START", url, "HTTP", r.status_code)
        return None
    soup = BeautifulSoup(r.text, "html.parser")

    # –Ω–∞–π–¥—ë–º –¥–≤–∞ h3 —Å ¬´—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–≥—Ä–æ–∫–æ–≤¬ª
    h3s = []
    for h3 in soup.find_all("h3"):
        t = (h3.get_text(" ", strip=True) or "")
        if re.search(r"—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–≥—Ä–æ–∫–æ–≤", t, flags=re.IGNORECASE):
            h3s.append(h3)
    if len(h3s) < 2:
        logdbg("PARSE START", url, "NO H3 STATS")
        return None

    # –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–∏—à—É—Ç ¬´–ö–æ–º–∞–Ω–¥–∞. —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–≥—Ä–æ–∫–æ–≤¬ª, –∏–Ω–æ–≥–¥–∞ –Ω–∞–æ–±–æ—Ä–æ—Ç
    def team_from_h3(h3):
        t = h3.get_text(" ", strip=True)
        m = re.match(r"\s*(.+?)\.\s*—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–≥—Ä–æ–∫–æ–≤\s*$", t, flags=re.IGNORECASE)
        if m:
            return m.group(1).strip('¬´¬ª" ')
        return (t.replace("—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–≥—Ä–æ–∫–æ–≤", "").strip()).strip('¬´¬ª" ')

    teamA_name = team_from_h3(h3s[0]) or TEAM_RU.get(a_abbr, a_abbr)
    teamB_name = team_from_h3(h3s[1]) or TEAM_RU.get(b_abbr, b_abbr)

    playersA, scoreA = parse_stats_table(h3s[0])
    playersB, scoreB = parse_stats_table(h3s[1])

    # –µ—Å–ª–∏ —Å—á—ë—Ç–∞ –Ω–µ—Ç –≤ ¬´–ò—Ç–æ–≥–æ¬ª, –ø–æ–ø—Ä–æ–±—É–µ–º –∏–∑ –æ–±—â–µ–π ¬´XX:YY¬ª
    if not (scoreA and scoreB):
        txt = soup.get_text(" ", strip=True)
        m = re.search(r"\b(\d{1,3})\s*:\s*(\d{1,3})\b", txt)
        if m:
            scoreA = scoreA or int(m.group(1))
            scoreB = scoreB or int(m.group(2))

    ot = detect_ot(soup)

    logdbg("PARSE TEAMS", teamA_name, teamB_name, "SCORES", scoreA or 0, scoreB or 0,
           "A_rows", len(playersA), "B_rows", len(playersB))

    return {
        "url": url,
        "teams": [
            {"abbr": a_abbr, "name_ru": teamA_name, "score": scoreA or 0, "players": playersA},
            {"abbr": b_abbr, "name_ru": teamB_name, "score": scoreB or 0, "players": playersB},
        ],
        "ot": ot,
    }

# ========= PICKING & FORMAT =========
def is_double_double(p: dict) -> bool:
    cats = [p["pts"], p["reb"], p["ast"], p["stl"], p["blk"]]
    return sum(1 for v in cats if v >= 10) >= 2

def pick_players_for_team(team_abbr: str, plist: list[dict]) -> list[dict]:
    if not plist:
        return []
    plist_sorted = sorted(plist, key=lambda x: (x["pts"], x["reb"], x["ast"]), reverse=True)
    picked = []

    # —Å–ø–µ—Ü-–∏–≥—Ä–æ–∫–∏
    want_last = "–î—ë–º–∏–Ω" if team_abbr == "BKN" else ("–ì–æ–ª–¥–∏–Ω" if team_abbr == "MIA" else None)
    special = None
    if want_last:
        for p in plist:
            if p["name_ru"].split()[-1].strip().lower() == want_last.lower():
                special = p; break

    best = plist_sorted[0]; picked.append(best)

    if special and special not in picked:
        picked.append(special)
    else:
        for p in plist_sorted[1:]:
            if p in picked: 
                continue
            if p["pts"] >= 20 or is_double_double(p) or p["stl"] >= 5 or p["blk"] >= 5:
                picked.append(p)
                break

    return picked[:2]

def initials_plus_surname(name_ru: str) -> str:
    parts = [w for w in name_ru.split() if w]
    if len(parts) <= 1: return name_ru
    return f"{parts[0][0]}. {parts[-1]}"

def fmt_player_line(p: dict, force_top3: bool = False) -> str:
    name = initials_plus_surname(p["name_ru"])
    pts, reb, ast, stl, blk = p["pts"], p["reb"], p["ast"], p["stl"], p["blk"]

    if force_top3:
        extras = [
            ("–ø–æ–¥–±–æ—Ä","–ø–æ–¥–±–æ—Ä–∞","–ø–æ–¥–±–æ—Ä–æ–≤", reb),
            ("–ø–µ—Ä–µ–¥–∞—á–∞","–ø–µ—Ä–µ–¥–∞—á–∏","–ø–µ—Ä–µ–¥–∞—á", ast),
            ("–ø–µ—Ä–µ—Ö–≤–∞—Ç","–ø–µ—Ä–µ—Ö–≤–∞—Ç–∞","–ø–µ—Ä–µ—Ö–≤–∞—Ç–æ–≤", stl),
            ("–±–ª–æ–∫-—à–æ—Ç","–±–ª–æ–∫-—à–æ—Ç–∞","–±–ª–æ–∫-—à–æ—Ç–æ–≤", blk),
        ]
        extras = [(w1,w2,w3,val) for (w1,w2,w3,val) in extras if val and val>0]
        extras.sort(key=lambda t: t[3], reverse=True)
        extras = extras[:3]
        parts = [f"{name}: {pts} {ru_plural(pts, ('–æ—á–∫–æ','–æ—á–∫–∞','–æ—á–∫–æ–≤'))}"]
        for (w1,w2,w3,val) in extras:
            parts.append(f"{val} {ru_plural(val,(w1,w2,w3))}")
        return "<span class=\"tg-spoiler\">" + ", ".join(parts) + "</span>"

    parts = [f"{name}: {pts} {ru_plural(pts, ('–æ—á–∫–æ','–æ—á–∫–∞','–æ—á–∫–æ–≤'))}"]
    if reb >= 5: parts.append(f"{reb} {ru_plural(reb, ('–ø–æ–¥–±–æ—Ä','–ø–æ–¥–±–æ—Ä–∞','–ø–æ–¥–±–æ—Ä–æ–≤'))}")
    if ast >= 5: parts.append(f"{ast} {ru_plural(ast, ('–ø–µ—Ä–µ–¥–∞—á–∞','–ø–µ—Ä–µ–¥–∞—á–∏','–ø–µ—Ä–µ–¥–∞—á'))}")
    if stl >= 4: parts.append(f"{stl} {ru_plural(stl, ('–ø–µ—Ä–µ—Ö–≤–∞—Ç','–ø–µ—Ä–µ—Ö–≤–∞—Ç–∞','–ø–µ—Ä–µ—Ö–≤–∞—Ç–æ–≤'))}")
    if blk >= 4: parts.append(f"{blk} {ru_plural(blk, ('–±–ª–æ–∫-—à–æ—Ç','–±–ª–æ–∫-—à–æ—Ç–∞','–±–ª–æ–∫-—à–æ—Ç–æ–≤'))}")
    return "<span class=\"tg-spoiler\">" + ", ".join(parts) + "</span>"

# ========= BUILD POST =========
def build_post(d: date) -> str:
    links = fetch_day_links(d)
    games = []
    for u in links:
        try:
            g = parse_sports_match(u)
            if not g:
                continue
            games.append(g)
        except Exception as e:
            logdbg("PARSE ERROR", u, repr(e))

    n = len(games)
    title = (
        f"–ù–ë–ê ‚Ä¢ {ru_date(d)} ‚Ä¢ {n} {ru_plural(n, ('–º–∞—Ç—á','–º–∞—Ç—á–∞','–º–∞—Ç—á–µ–π'))}\n"
        "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞–¥—ë–∂–Ω–æ —Å–ø—Ä—è—Ç–∞–Ω—ã üëá\n"
        "‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì\n\n"
    )

    if n == 0:
        return title.rstrip()

    lines = []
    for idx, g in enumerate(games):
        t1, t2 = g["teams"][0], g["teams"][1]
        a_win = t1["score"] > t2["score"]
        b_win = t2["score"] > t1["score"]

        name1 = TEAM_RU.get(t1["abbr"], t1["name_ru"])
        name2 = TEAM_RU.get(t2["abbr"], t2["name_ru"])
        e1 = team_emoji(t1["abbr"])
        e2 = team_emoji(t2["abbr"])

        scoreA = f"<b>{t1['score']}</b>" if a_win else f"{t1['score']}"
        scoreB = f"<b>{t2['score']}</b>" if b_win else f"{t2['score']}"
        ot_tag = " (–û–¢)" if g["ot"] else ""

        lines.append(f"{e1} {name1}: <span class=\"tg-spoiler\">{scoreA}</span>")
        lines.append(f"{e2} {name2}: <span class=\"tg-spoiler\">{scoreB}</span>{ot_tag}")
        lines.append("")  # –æ—Ç—Å—Ç—É–ø –º–µ–∂–¥—É —Å—á—ë—Ç–æ–º –∏ –∏–≥—Ä–æ–∫–∞–º–∏

        # –∫–æ–º–∞–Ω–¥–∞ 1
        picked1 = pick_players_for_team(t1["abbr"], t1["players"])
        for p in picked1:
            force = (t1["abbr"] == "BKN" and p["name_ru"].split()[-1] == "–î—ë–º–∏–Ω") or \
                    (t1["abbr"] == "MIA" and p["name_ru"].split()[-1] == "–ì–æ–ª–¥–∏–Ω")
            lines.append(fmt_player_line(p, force_top3=force))

        if picked1:
            lines.append("")  # –æ—Ç—Å—Ç—É–ø –º–µ–∂–¥—É –∫–æ–º–∞–Ω–¥–∞–º–∏ –≤ –±–ª–æ–∫–µ –∏–≥—Ä–æ–∫–æ–≤

        # –∫–æ–º–∞–Ω–¥–∞ 2
        picked2 = pick_players_for_team(t2["abbr"], t2["players"])
        for p in picked2:
            force = (t2["abbr"] == "BKN" and p["name_ru"].split()[-1] == "–î—ë–º–∏–Ω") or \
                    (t2["abbr"] == "MIA" and p["name_ru"].split()[-1] == "–ì–æ–ª–¥–∏–Ω")
            lines.append(fmt_player_line(p, force_top3=force))

        if idx + 1 < len(games):
            lines.append("")
            lines.append("‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì‚Äì")
            lines.append("")

    return title + "\n".join(lines).strip()

# ========= TELEGRAM =========
def tg_send(text: str):
    if not (BOT_TOKEN and CHAT_ID):
        raise RuntimeError("TELEGRAM_BOT_TOKEN / TELEGRAM_CHAT_ID –Ω–µ –∑–∞–¥–∞–Ω—ã")
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    payload = {
        "chat_id": CHAT_ID,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": True,
    }
    r = S.post(url, json=payload, timeout=25)
    if r.status_code != 200:
        raise RuntimeError(f"Telegram error {r.status_code}: {r.text}")

# ========= MAIN =========
if __name__ == "__main__":
    try:
        day = pick_best_report_date()
        logdbg("DAY PICKED", day.isoformat())
        post = build_post(day)
        tg_send(post)
        print("OK")
    except Exception as e:
        print("ERROR:", repr(e), file=sys.stderr)
        sys.exit(1)
